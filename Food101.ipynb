{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXb-yoTv1cbd",
        "outputId": "ff97a1e1-1672-4980-caee-d0ef474635d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Collecting torch\n",
            "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.17.1+cu121\n",
            "    Uninstalling torchvision-0.17.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.17.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.2.2 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 torchvision-0.17.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r75DEbx1Zb_",
        "outputId": "c46301d7-cfa9-4c35-a7f7-0a2e253a74fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-w0Ib6lTWC3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Torch version: {torch.__version__}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUm3nLF1TjTT",
        "outputId": "2a9b1e38-ccf8-4add-f4ec-7828eaf4c76a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 2.2.2+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSgB9HvJpNIg",
        "outputId": "fb2727ff-1070-4520-de05-d65e0d4e0336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mean and std according to https://pytorch.org/vision/main/models/generated/torchvision.models.resnet34.html\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]"
      ],
      "metadata": {
        "id": "EPGIfjQcnRmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "                                transforms.Resize(256),\n",
        "                                transforms.RandomResizedCrop(224),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean, std)])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "                                transforms.Resize(256),\n",
        "                                transforms.CenterCrop(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean, std)])"
      ],
      "metadata": {
        "id": "Di9eFHVvo1tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.Food101(root='./drive/My Drive/deep_learning/datasets',\n",
        "                                        split ='train',\n",
        "                                        download=True,\n",
        "                                        transform=train_transform)"
      ],
      "metadata": {
        "id": "MhzygA7Fo7Um",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ee8418d-fcf1-4a24-beb5-370d3496c432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz to ./drive/My Drive/deep_learning/datasets/food-101.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4996278331/4996278331 [05:46<00:00, 14405002.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./drive/My Drive/deep_learning/datasets/food-101.tar.gz to ./drive/My Drive/deep_learning/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset = torchvision.datasets.Food101(root='./drive/My Drive/deep_learning/datasets',\n",
        "                                       split='test',\n",
        "                                       download=True,\n",
        "                                       transform=train_transform)"
      ],
      "metadata": {
        "id": "G2zq1TjMppbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1000\n",
        "num_workers = 4"
      ],
      "metadata": {
        "id": "2b94HK2pqfIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=num_workers)"
      ],
      "metadata": {
        "id": "ppbs4p_aqmyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testloader = torch.utils.data.DataLoader(testset,\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=False,\n",
        "                                         num_workers=num_workers)"
      ],
      "metadata": {
        "id": "lzmBKJR90iW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainset.classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k5dVSUC0VtY",
        "outputId": "63590d69-75c2-4dce-9d2d-a8a57439f86d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli', 'caprese_salad', 'carrot_cake', 'ceviche', 'cheese_plate', 'cheesecake', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros', 'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel', 'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad', 'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque', 'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta', 'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad', 'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi', 'tacos', 'takoyaki', 'tiramisu', 'tuna_tartare', 'waffles']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet34(pretrained=True)"
      ],
      "metadata": {
        "id": "01Sy5bWe07GB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08cefe1b-c38b-4898-d325-07170da4f9a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 96.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDeQKwGe1SY1",
        "outputId": "fd5568dc-2283-4221-efab-0afe3e2e633e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "ResNet                                   --\n",
              "├─Conv2d: 1-1                            9,408\n",
              "├─BatchNorm2d: 1-2                       128\n",
              "├─ReLU: 1-3                              --\n",
              "├─MaxPool2d: 1-4                         --\n",
              "├─Sequential: 1-5                        --\n",
              "│    └─BasicBlock: 2-1                   --\n",
              "│    │    └─Conv2d: 3-1                  36,864\n",
              "│    │    └─BatchNorm2d: 3-2             128\n",
              "│    │    └─ReLU: 3-3                    --\n",
              "│    │    └─Conv2d: 3-4                  36,864\n",
              "│    │    └─BatchNorm2d: 3-5             128\n",
              "│    └─BasicBlock: 2-2                   --\n",
              "│    │    └─Conv2d: 3-6                  36,864\n",
              "│    │    └─BatchNorm2d: 3-7             128\n",
              "│    │    └─ReLU: 3-8                    --\n",
              "│    │    └─Conv2d: 3-9                  36,864\n",
              "│    │    └─BatchNorm2d: 3-10            128\n",
              "│    └─BasicBlock: 2-3                   --\n",
              "│    │    └─Conv2d: 3-11                 36,864\n",
              "│    │    └─BatchNorm2d: 3-12            128\n",
              "│    │    └─ReLU: 3-13                   --\n",
              "│    │    └─Conv2d: 3-14                 36,864\n",
              "│    │    └─BatchNorm2d: 3-15            128\n",
              "├─Sequential: 1-6                        --\n",
              "│    └─BasicBlock: 2-4                   --\n",
              "│    │    └─Conv2d: 3-16                 73,728\n",
              "│    │    └─BatchNorm2d: 3-17            256\n",
              "│    │    └─ReLU: 3-18                   --\n",
              "│    │    └─Conv2d: 3-19                 147,456\n",
              "│    │    └─BatchNorm2d: 3-20            256\n",
              "│    │    └─Sequential: 3-21             8,448\n",
              "│    └─BasicBlock: 2-5                   --\n",
              "│    │    └─Conv2d: 3-22                 147,456\n",
              "│    │    └─BatchNorm2d: 3-23            256\n",
              "│    │    └─ReLU: 3-24                   --\n",
              "│    │    └─Conv2d: 3-25                 147,456\n",
              "│    │    └─BatchNorm2d: 3-26            256\n",
              "│    └─BasicBlock: 2-6                   --\n",
              "│    │    └─Conv2d: 3-27                 147,456\n",
              "│    │    └─BatchNorm2d: 3-28            256\n",
              "│    │    └─ReLU: 3-29                   --\n",
              "│    │    └─Conv2d: 3-30                 147,456\n",
              "│    │    └─BatchNorm2d: 3-31            256\n",
              "│    └─BasicBlock: 2-7                   --\n",
              "│    │    └─Conv2d: 3-32                 147,456\n",
              "│    │    └─BatchNorm2d: 3-33            256\n",
              "│    │    └─ReLU: 3-34                   --\n",
              "│    │    └─Conv2d: 3-35                 147,456\n",
              "│    │    └─BatchNorm2d: 3-36            256\n",
              "├─Sequential: 1-7                        --\n",
              "│    └─BasicBlock: 2-8                   --\n",
              "│    │    └─Conv2d: 3-37                 294,912\n",
              "│    │    └─BatchNorm2d: 3-38            512\n",
              "│    │    └─ReLU: 3-39                   --\n",
              "│    │    └─Conv2d: 3-40                 589,824\n",
              "│    │    └─BatchNorm2d: 3-41            512\n",
              "│    │    └─Sequential: 3-42             33,280\n",
              "│    └─BasicBlock: 2-9                   --\n",
              "│    │    └─Conv2d: 3-43                 589,824\n",
              "│    │    └─BatchNorm2d: 3-44            512\n",
              "│    │    └─ReLU: 3-45                   --\n",
              "│    │    └─Conv2d: 3-46                 589,824\n",
              "│    │    └─BatchNorm2d: 3-47            512\n",
              "│    └─BasicBlock: 2-10                  --\n",
              "│    │    └─Conv2d: 3-48                 589,824\n",
              "│    │    └─BatchNorm2d: 3-49            512\n",
              "│    │    └─ReLU: 3-50                   --\n",
              "│    │    └─Conv2d: 3-51                 589,824\n",
              "│    │    └─BatchNorm2d: 3-52            512\n",
              "│    └─BasicBlock: 2-11                  --\n",
              "│    │    └─Conv2d: 3-53                 589,824\n",
              "│    │    └─BatchNorm2d: 3-54            512\n",
              "│    │    └─ReLU: 3-55                   --\n",
              "│    │    └─Conv2d: 3-56                 589,824\n",
              "│    │    └─BatchNorm2d: 3-57            512\n",
              "│    └─BasicBlock: 2-12                  --\n",
              "│    │    └─Conv2d: 3-58                 589,824\n",
              "│    │    └─BatchNorm2d: 3-59            512\n",
              "│    │    └─ReLU: 3-60                   --\n",
              "│    │    └─Conv2d: 3-61                 589,824\n",
              "│    │    └─BatchNorm2d: 3-62            512\n",
              "│    └─BasicBlock: 2-13                  --\n",
              "│    │    └─Conv2d: 3-63                 589,824\n",
              "│    │    └─BatchNorm2d: 3-64            512\n",
              "│    │    └─ReLU: 3-65                   --\n",
              "│    │    └─Conv2d: 3-66                 589,824\n",
              "│    │    └─BatchNorm2d: 3-67            512\n",
              "├─Sequential: 1-8                        --\n",
              "│    └─BasicBlock: 2-14                  --\n",
              "│    │    └─Conv2d: 3-68                 1,179,648\n",
              "│    │    └─BatchNorm2d: 3-69            1,024\n",
              "│    │    └─ReLU: 3-70                   --\n",
              "│    │    └─Conv2d: 3-71                 2,359,296\n",
              "│    │    └─BatchNorm2d: 3-72            1,024\n",
              "│    │    └─Sequential: 3-73             132,096\n",
              "│    └─BasicBlock: 2-15                  --\n",
              "│    │    └─Conv2d: 3-74                 2,359,296\n",
              "│    │    └─BatchNorm2d: 3-75            1,024\n",
              "│    │    └─ReLU: 3-76                   --\n",
              "│    │    └─Conv2d: 3-77                 2,359,296\n",
              "│    │    └─BatchNorm2d: 3-78            1,024\n",
              "│    └─BasicBlock: 2-16                  --\n",
              "│    │    └─Conv2d: 3-79                 2,359,296\n",
              "│    │    └─BatchNorm2d: 3-80            1,024\n",
              "│    │    └─ReLU: 3-81                   --\n",
              "│    │    └─Conv2d: 3-82                 2,359,296\n",
              "│    │    └─BatchNorm2d: 3-83            1,024\n",
              "├─AdaptiveAvgPool2d: 1-9                 --\n",
              "├─Linear: 1-10                           513,000\n",
              "=================================================================\n",
              "Total params: 21,797,672\n",
              "Trainable params: 21,797,672\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = model.fc.in_features\n",
        "print(f'The number of features on the pretrained model: {num_features}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzJ_FEtc1zIW",
        "outputId": "253f8e10-7386-420f-d16e-f81a17ff612a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of features on the pretrained model: 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_food_classes = len(trainset.classes)\n",
        "model.fc = nn.Linear(num_features, num_food_classes)"
      ],
      "metadata": {
        "id": "chksHcv-2GwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "optimizer = optim.Adam(model.parameters(),\n",
        "                       lr=learning_rate)"
      ],
      "metadata": {
        "id": "9BKCXLZ6UMHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer,\n",
        "                                       step_size=10,\n",
        "                                       gamma=0.9)"
      ],
      "metadata": {
        "id": "IiLrK9cL2zgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Brb3ezvb3Flg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6xgkxUG43RV7",
        "outputId": "5f109293-ca6c-4631-8cde-b38f38d9dab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_average_validation_loss_and_accuracy(model,\n",
        "                                    testloader,\n",
        "                                    criterion,\n",
        "                                    device):\n",
        "  model.eval()\n",
        "  val_loss = 0.0\n",
        "  correct= 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "  average_val_loss = val_loss / len(testloader.dataset)\n",
        "  accuracy = correct/total\n",
        "  return (average_val_loss, accuracy)"
      ],
      "metadata": {
        "id": "ttNe7Xt4bY96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_loss_and_accuracy_details(epoch_number,\n",
        "                                   total_number_epochs,\n",
        "                                   model,\n",
        "                                   testloader,\n",
        "                                   criterion,\n",
        "                                   device):\n",
        "  average_val_loss, accuracy = compute_average_validation_loss_and_accuracy(model, testloader, criterion, device)\n",
        "  print(f'Epoch [{epoch+1}/{total_number_epochs}], Validation Loss: {average_val_loss:.4f}, Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "k0dExXb8ePro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint_model(epoch,\n",
        "                          model_state_dict,\n",
        "                          optimizer_state_dict,\n",
        "                          loss,\n",
        "                          checkpoint_path):\n",
        "  checkpoint_path = f'{checkpoint_path}model{epoch}.pt'\n",
        "  torch.save({\n",
        "      'epoch': epoch,\n",
        "      'model_state_dict': model_state_dict,\n",
        "      'optimizer_state_dict': optimizer_state_dict,\n",
        "      'loss': loss\n",
        "  }, checkpoint_path)"
      ],
      "metadata": {
        "id": "GwI4N5m-jAgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = './drive/My Drive/deep_learning/checkpoints/'"
      ],
      "metadata": {
        "id": "LlcCQWyWiQm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_training_epochs = 50"
      ],
      "metadata": {
        "id": "2xspfMMTbDjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "for epoch in range(num_training_epochs):\n",
        "  print(f'Training - epoch {epoch + 1}.')\n",
        "\n",
        "  model.train()\n",
        "  for inputs, labels in trainloader:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if(epoch % 3 == 0):\n",
        "    save_checkpoint_model(epoch, model.state_dict(), optimizer.state_dict(), loss, checkpoint_path)\n",
        "    show_loss_and_accuracy_details(epoch, num_training_epochs, model, testloader, criterion, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AThcQBXQ3jhY",
        "outputId": "6153cc09-839e-4757-e13f-d2046fdd71a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - epoch 1.\n",
            "Epoch [1/50], Validation Loss: 2.0568, Accuracy: 0.4879\n",
            "Training - epoch 2.\n",
            "Training - epoch 3.\n",
            "Training - epoch 4.\n",
            "Epoch [4/50], Validation Loss: 1.4692, Accuracy: 0.6187\n",
            "Training - epoch 5.\n",
            "Training - epoch 6.\n",
            "Training - epoch 7.\n",
            "Epoch [7/50], Validation Loss: 1.4899, Accuracy: 0.6211\n",
            "Training - epoch 8.\n",
            "Training - epoch 9.\n",
            "Training - epoch 10.\n",
            "Epoch [10/50], Validation Loss: 1.2318, Accuracy: 0.6785\n",
            "Training - epoch 11.\n",
            "Training - epoch 12.\n",
            "Training - epoch 13.\n",
            "Epoch [13/50], Validation Loss: 1.2505, Accuracy: 0.6877\n",
            "Training - epoch 14.\n",
            "Training - epoch 15.\n",
            "Training - epoch 16.\n",
            "Epoch [16/50], Validation Loss: 1.1291, Accuracy: 0.7098\n",
            "Training - epoch 17.\n",
            "Training - epoch 18.\n",
            "Training - epoch 19.\n",
            "Epoch [19/50], Validation Loss: 1.2206, Accuracy: 0.7036\n",
            "Training - epoch 20.\n",
            "Training - epoch 21.\n",
            "Training - epoch 22.\n",
            "Epoch [22/50], Validation Loss: 1.1505, Accuracy: 0.7169\n",
            "Training - epoch 23.\n",
            "Training - epoch 24.\n",
            "Training - epoch 25.\n",
            "Epoch [25/50], Validation Loss: 1.1461, Accuracy: 0.7230\n",
            "Training - epoch 26.\n",
            "Training - epoch 27.\n",
            "Training - epoch 28.\n",
            "Epoch [28/50], Validation Loss: 1.1490, Accuracy: 0.7196\n",
            "Training - epoch 29.\n",
            "Training - epoch 30.\n",
            "Training - epoch 31.\n",
            "Epoch [31/50], Validation Loss: 1.1719, Accuracy: 0.7215\n",
            "Training - epoch 32.\n",
            "Training - epoch 33.\n",
            "Training - epoch 34.\n",
            "Epoch [34/50], Validation Loss: 1.2227, Accuracy: 0.7091\n",
            "Training - epoch 35.\n",
            "Training - epoch 36.\n",
            "Training - epoch 37.\n",
            "Epoch [37/50], Validation Loss: 1.1250, Accuracy: 0.7377\n",
            "Training - epoch 38.\n",
            "Training - epoch 39.\n",
            "Training - epoch 40.\n",
            "Epoch [40/50], Validation Loss: 1.1780, Accuracy: 0.7309\n",
            "Training - epoch 41.\n",
            "Training - epoch 42.\n",
            "Training - epoch 43.\n",
            "Epoch [43/50], Validation Loss: 1.2562, Accuracy: 0.7228\n",
            "Training - epoch 44.\n",
            "Training - epoch 45.\n",
            "Training - epoch 46.\n",
            "Epoch [46/50], Validation Loss: 1.1760, Accuracy: 0.7292\n",
            "Training - epoch 47.\n",
            "Training - epoch 48.\n",
            "Training - epoch 49.\n",
            "Epoch [49/50], Validation Loss: 1.2038, Accuracy: 0.7286\n",
            "Training - epoch 50.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  _ , accuracy = compute_average_validation_loss_and_accuracy(model, testloader, criterion, device)\n",
        "  print(f'Accuracy of the model on the test images: {accuracy*100:.4f}')\n"
      ],
      "metadata": {
        "id": "2JXDgH7qXu1s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e505a0c4-1d96-448d-d8b1-d60ede006fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the test images: 72.6139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wWT3SIGs3Ca1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, './drive/My Drive/deep_learning/food101model.pt')"
      ],
      "metadata": {
        "id": "0cSDxt_JuC08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx\n",
        "!pip install onnxscript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmZvYDWjf7Z8",
        "outputId": "b33fd7d1-cc9e-4e44-f739-c3fb345f396e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.16.0\n",
            "Collecting onnxscript\n",
            "  Downloading onnxscript-0.1.0.dev20240413-py3-none-any.whl (582 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.4/582.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnxscript) (1.25.2)\n",
            "Requirement already satisfied: onnx>=1.15 in /usr/local/lib/python3.10/dist-packages (from onnxscript) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from onnxscript) (4.11.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.15->onnxscript) (3.20.3)\n",
            "Installing collected packages: onnxscript\n",
            "Successfully installed onnxscript-0.1.0.dev20240413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input = torch.randn(1, 3, 224, 224).cuda()\n",
        "\n",
        "onnx_file_path = \"./drive/My Drive/deep_learning/food101model.onnx\"\n",
        "\n",
        "torch.onnx.export(model, sample_input, onnx_file_path)"
      ],
      "metadata": {
        "id": "ETNP3LEtgY3C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}